<!doctype html>
<html class="" lang="en">
<head>
  <meta charset="utf-8">
  <meta http-equiv="x-ua-compatible" content="ie=edge">
  <title>Omid Aramoon Portfolio</title>
  <meta name="description" content="">
  <meta name="viewport" content="width=device-width, initial-scale=1">

  <!-- inject:css -->
  <!-- endinject -->

  <link href="https://fonts.googleapis.com/css?family=Lato:400,700,900|Lora:400,400i,700" rel="stylesheet">
  
<link rel="stylesheet" href="css/main-blue.css" data-pin="img/icofont-location-pin--blue.png">


  <!-- HTML5 Shim and Respond.js IE8 support of HTML5 elements and media queries -->
  <!-- WARNING: Respond.js doesn't work if you view the page via file:// -->
  <!--[if lt IE 9]>
  <script src="https://oss.maxcdn.com/libs/html5shiv/3.7.0/html5shiv.js"></script>
  <script src="https://oss.maxcdn.com/libs/respond.js/1.4.2/respond.min.js"></script>
  <![endif]-->
  <!-- Yandex.Metrika counter -->
  <script type="text/javascript">
      (function (d, w, c) {
          (w[c] = w[c] || []).push(function() {
              try {
                  w.yaCounter42961429 = new Ya.Metrika({
                      id:42961429,
                      clickmap:true,
                      trackLinks:true,
                      accurateTrackBounce:true,
                      webvisor:true,
                      trackHash:true
                  });
              } catch(e) { }
          });

          var n = d.getElementsByTagName("script")[0],
              s = d.createElement("script"),
              f = function () { n.parentNode.insertBefore(s, n); };
          s.type = "text/javascript";
          s.async = true;
          s.src = "https://mc.yandex.ru/metrika/watch.js";

          if (w.opera == "[object Opera]") {
              d.addEventListener("DOMContentLoaded", f, false);
          } else { f(); }
      })(document, window, "yandex_metrika_callbacks");
  </script>
  <noscript><div><img src="https://mc.yandex.ru/watch/42961429" style="position:absolute; left:-9999px;" alt="" /></div></noscript>
  <!-- /Yandex.Metrika counter -->
</head>
<body>
    <!--[if lt IE 10]>
        <p class="browserupgrade">You are using an <strong>outdated</strong> browser. Please <a href="http://browsehappy.com/">upgrade your browser</a> to improve your experience.</p>
    <![endif]-->

    <div class="ie-overflow-fix" style="overflow:hidden;">
      


<link rel="stylesheet" href="css/main-blue.css" data-pin="img/icofont-location-pin--blue.png">





<header class="c-main-header">

  <div class="o-container">

    <!-- NAVIGATION -->
    <div class="c-main-header__nav-wrapper" data-menuAnimated="true">
      <nav class="c-main-nav js-main-nav">
        <ul class="c-main-nav__list nav-fixed--is-active js-main-nav__list">
          <li class="c-main-nav__item"><a href="#section-about" class="c-main-nav__link" data-navPosition="1"><span></span>About</a></li>
          <li class="c-main-nav__item"><a href="#section-education" class="c-main-nav__link" data-navPosition="2"><span></span>Education</a></li>
          <li class="c-main-nav__item"><a href="#section-research" class="c-main-nav__link" data-navPosition="3"><span></span>Research</a></li>
          <li class="c-main-nav__item"><a href="#section-publications" class="c-main-nav__link" data-navPosition="4"><span></span>ML publications</a></li>
          <li class="c-main-nav__item"><a href="#section-publications-1" class="c-main-nav__link" data-navPosition="5"><span></span>EDA publications</a></li>
          <li class="c-main-nav__item"><a href="#section-contacts" class="c-main-nav__link" data-navPosition="6"><span></span>Contacts</a></li>
        </ul>
        <div class="c-main-nav__bars js-main-nav-toggle">
          <span></span>
          <span></span>
          <span></span>
        </div>
      </nav>
    </div>
    <!-- NAVIGATION END -->

    <!-- ABOUT SECTION-->
    <div id="section-about" class="c-screen-about o-screen-about" data-contentPosition="1">
      <div class="o-screen-about__col">
        <figure class="c-screen-about__image">
          <span></span>
          <img src="pic/me.JPG" alt="">
        </figure>
      </div>
      <div class="o-screen-about__col">
        <h1 class="u-mb-5">Omid Aramoon</h1>
        <span class="c-screen-about__caption">Graduate Research Assistant</span>
        <ul class="c-socials u-mb-35">
          <li class="c-socials__item">
            <a href="https://www.linkedin.com/in/omid-aramoon?lipi=urn%3Ali%3Apage%3Ad_flagship3_profile_view_base_contact_details%3B1ZfCoMzVRTSMlEOkYPIqrA%3D%3D" class="c-socials__link">
              <i class="icofont icofont-brand-linkedin"></i>
            </a>
          </li>
          <li class="c-socials__item">
            <a href="https://github.com/oaramoon" class="c-socials__link">
              <i class="icofont icofont-social-github"></i>
          </a>
         </li>
        </ul>
        <p class="u-mb-10"><span class="u-block">Hello!</span> I’m a researcher at the Maryland Cybersecurity Center at the University of Maryland.
          <span class="u-block">I started my Ph.D. working on security problems in hardware design including Intellectual Property (IP) protection, locking, and fingerprinting schemes, which led to several publications at prestigious conferences. I later turned my attention to solving similar security problems concerning machine learning (ML) and deep learning (DL) systems and published several papers related to applied ML/DL security.</span>
          
          <span class="u-block">My areas of interest in research are <strong>security of deep learning and machine learning systems against training and test time adversarial attacks.</strong></span>

          I am confident in my research skills, knowledge of deep learning and machine learning concepts, and ability to develop complex ML/DL algorithms using Python and TensorFlow.
          <strong>I am expected to graduate in August 2022</strong></p>

        <a class="c-button c-button--bold-text u-mb-30" href="./Omid_Aramoon_CV.pdf">download cv</a>

        <h3 class="u-mb-10">Latest publications:</h3>
        <a href="https://arxiv.org/abs/2102.05561"><p class="u-mb-10" >"Meta Federated Learning” published on DPML workshop in International Conference on Learning Representations (ICLR-21).</p></a>
        <a href="https://dl.acm.org/doi/abs/10.1145/3453688.3461750"><p class="u-mb-10" >“Provably Accurate Memory Fault Detection Method for Deep Neural Networks” published on Proceedings of the GLSVLSI-21.</p></a>
        <a href="https://ieeexplore.ieee.org/document/9586290"><p class="u-mb-10" >“AID: Attesting the Integrity of Deep Neural Networks” published on 2021 58th ACM/IEEE Design Automation Conference (DAC-21).</p></a>
      </div>
    </div>

  </div>

</header>





<main class="o-main">
  <!-- EDUCATION -->
  <div id="section-education" class="o-container js-main-container  wow1 fadeIn" data-contentPosition="2">
    <div class="c-section-heading">
      <h2 class="c-section-heading__header">Education</h2>
    </div>

    <div class="c-screen-education o-screen-education">
      <div class="o-screen-education__col">
        <div class="c-timeline">
          <ul class="c-timeline__list">
            <li class="c-timeline__item">
              <header class="c-timeline__header">
                <span class="c-timeline__time">In Progress</span>
                <span class="c-timeline__line"></span>
                <h4 class="c-timeline__heading"><span class="u-block">Doctor of Philosophy</span>
                <span class="u-block">Electrical and Computer Engineering</span>
                <span class="u-block">University of Maryland, College Park, MD</span></h4>
              </header>
            </li>
            <li class="c-timeline__item">
              <header class="c-timeline__header">
                <span class="c-timeline__time">2016-2021</span>
                <span class="c-timeline__line"></span>
                <h4 class="c-timeline__heading"><span class="u-block">Master of Science</span>
                <span class="u-block">Electrical and Computer Engineering</span>
                <span class="u-block">University of Maryland, College Park, MD</span></h4>
                </h4>
              </header>
            </li>
            <li class="c-timeline__item">
              <header class="c-timeline__header">
                <span class="c-timeline__time">2011-2016</span>
                <span class="c-timeline__line"></span>
                <h4 class="c-timeline__heading"><span class="u-block">Bachelor of Science</span>
                <span class="u-block">Computer Engineering</span>
                <span class="u-block">Sharif University of Technology, Tehran, Iran</span></h4>
              </header>
            </li>
          </ul>
        </div>
      </div>
      <div class="o-screen-education__col o-screen-education__col--narrow">
        <figure class="c-screen-education__image">
          <img src="img/edu.jpg" alt="">
        </figure>
      </div>
    </div>
  </div>

  <!-- RESEARCH -->
  <div id="section-research" class="o-container   wow1 fadeIn" data-contentPosition="3">
    <div class="c-section-heading">
      <h2 class="c-section-heading__header">Research</h2>
    </div>

    <div class="c-screen-research o-screen-research">
      <div class="o-screen-research__col">
        <div class="c-card o-screen-research__cards js-cards">

          <div class="c-card__item js-toggle-modal">
            <div class="c-card__sizer"></div>
            <div class="c-card__inner">
              <div class="c-card__icon">
                
              </div>
              <h4 class="c-card__header">[on-going project] Power Side-channel Analysis for Security of AI </h4>
              <div class="c-card__content js-card-content">
              </div>
              <div class="c-card__modal-content js-card-modal-content">
                <p align="left" class="c-card__text">Physical phenomenons observed during the execution of algorithms on microelectronic devices are an inevitable side effect of their physical implementation. If such physical phenomena, known as side-channels, correlate with the sensitive data processed on the device, they may leak confidential information about the system's internal state and possibly compromise its security. For instance, the amount of time and energy needed for a device to execute certain computations may leak critical information about the operations taking place inside the device. The term Side-Channel Attack (SCA) describes the class of attacks in which the unintended information leaking from the implementation of algorithms is leveraged to extract confidential information. Historically, cryptographic systems have been the primary target of side-channel attacks, and a large number of studies have proposed a variety of techniques to break both symmetric and asymmetric encryption algorithms. However, recently, ML models, especially DNNs, have been shown to be vulnerable to side-channel attacks. In fact, several studies have proposed techniques to reverse-engineer certain properties of neural networks such as their architecture or parameters using the information obtained from physical and micro-architectural side-channel emitted during model execution. The security community often considers side channels as a negative side effect that could significantly weaken the security of algorithms implemented on microelectronic devices. In an alternative perspective, we’d like to view side channels as part of the design space that can provide constructive functionalities. I am currently investigating applications of power side channel analysis in detecting training and test time adversarial attacks against FPGA implementations of deep learning systems .</p>
              </div>
            </div>
            <div class="c-card__button">
              <button class="c-card__button-field" type="button"></button>
            </div>
          </div>


          <div class="c-card__item c-card__item--text-only" style="background-image:url(img/deco-triangle--blue.png)">
            <div class="c-card__sizer"></div>
            <div class="c-card__inner">
              <div class="c-card__content">
                <p class="c-card__text">I am really interested in <strong>Hardware Security and Security of Machine Learning and Deep Learning Systems.</strong></p>
              </div>
            </div>
          </div>

          <div class="c-card__item js-toggle-modal">
            <div class="c-card__sizer"></div>
            <div class="c-card__inner">
              <div class="c-card__icon">
                
              </div>
              <h4 class="c-card__header">Meta Federated Learning</h4>
              <div class="c-card__content js-card-content">
              </div>
              <div class="c-card__modal-content js-card-modal-content">
                <p align="left" class="c-card__text">Due to its distributed methodology alongside its privacy-preserving features, Federated Learning (FL) is vulnerable to training time adversarial attacks. In this study, our focus is on backdoor attacks in which the adversary's goal is to cause targeted misclassifications for inputs embedded with an adversarial trigger while maintaining an acceptable performance on the main learning task at hand. Contemporary defenses against backdoor attacks in federated learning require direct access to each individual client's update which is not feasible in recent FL settings where Secure Aggregation is deployed. In this study, we seek to answer the following question, Is it possible to defend against backdoor attacks when secure aggregation is in place?, a question that has not been addressed by prior arts. To this end, we propose Meta Federated Learning (Meta-FL), a novel variant of federated learning which not only is compatible with secure aggregation protocol but also facilitates defense against backdoor attacks. We perform a systematic evaluation of Meta-FL on two classification datasets: SVHN and GTSRB. The results show that Meta-FL not only achieves better utility than classic FL, but also enhances the performance of contemporary defenses in terms of robustness against adversarial attacks.</p>
                <p class="c-card__link-caption">Check my paper and presentation:</p>
                <a class="c-card__link" href="https://arxiv.org/abs/2102.05561">Meta Federated Learning</a>
                <a class="c-card__link" href="https://slideslive.com/38955549/meta-federated-learning?locale=en">My presentation on DPML workshop in ICLR-20</a>
              </div>
            </div>
            <div class="c-card__button">
              <button class="c-card__button-field" type="button"></button>
            </div>
          </div>

          <div class="c-card__item js-toggle-modal">
            <div class="c-card__sizer"></div>
            <div class="c-card__inner">
              <div class="c-card__icon">
                
              </div>
              <h4 class="c-card__header">Protecting Deep Neural Networks Against Integrity Breaches</h4>
              <div class="c-card__content js-card-content">
              </div>
              <div class="c-card__modal-content js-card-modal-content">
                <p align="left" class="c-card__text">Due to their crucial role in many decision-making tasks, Deep Neural Networks (DNNs) are common targets for a large array of integrity breaches. In this paper, we propose AID, a novel methodology to Attest the Integrity of DNNs. AID generates a set of test cases called edge-points that can reveal whether a model has been compromised. AID does not require access to parameters of the DNN and can work with a restricted black-box access to the model, which makes it applicable to most real life scenarios. Experimental results show that AID is highly effective and reliable.</p>
                <p class="c-card__link-caption">Check my paper:</p>
                <a class="c-card__link" href="https://ieeexplore.ieee.org/document/9586290">AID: Attesting the Integrity of Deep Neural Networks</a>
              </div>
            </div>
            <div class="c-card__button">
              <button class="c-card__button-field" type="button"></button>
            </div>
          </div>

          <div class="c-card__item js-toggle-modal">
            <div class="c-card__sizer"></div>
            <div class="c-card__inner">
              <div class="c-card__icon">
                
              </div>
              <h4 class="c-card__header">Fault Detection For Deep Neural Networks</h4>
              <div class="c-card__content js-card-content">
              </div>
              <div class="c-card__modal-content js-card-modal-content">
                <p align="left" class="c-card__text">Deep Neural Networks (DNNs) have been widely deployed in real-world systems, many of which have strict safety constraints. Soft errors on memory acceleration platforms for DNNs can degrade their inference accuracy and result in silent data corruption, which can have severe consequences in safety-critical applications. No doubt to say, efficient and effective techniques to detect and mitigate memory faults are needed. In this paper, we propose a novel methodology to diagnose the presence of faults in the memory of DNN accelerators. Our method queries the protected DNN with a set of specially crafted test cases that can accurately reveal if model parameters stored in the hardware are faulty. We provide a theoretical guarantee for the performance of our method and conduct systematic proof-of-concept experiments by simulating memory faults on computer vision models.</p>
                <p class="c-card__link-caption">Check my papers:</p>
                <a class="c-card__link" href="https://dl.acm.org/doi/abs/10.1145/3453688.3461750">Provably Accurate Memory Fault Detection Method for Deep Neural Networks</a>
              </div>
            </div>
            <div class="c-card__button">
              <button class="c-card__button-field" type="button"></button>
            </div>
          </div>

          <div class="c-card__item js-toggle-modal">
            <div class="c-card__sizer"></div>
            <div class="c-card__inner">
              <div class="c-card__icon">
                
              </div>
              <h4 class="c-card__header">Watermarking Deep Neural Networks</h4>
              <div class="c-card__content js-card-content">
              </div>
              <div class="c-card__modal-content js-card-modal-content">
                <p align="left" class="c-card__text">Engineering a top-notch deep learning model is an expensive procedure that involves collecting data, hiring human resources with expertise in machine learning, and providing high computational resources. For that reason, deep learning models are considered as valuable Intellectual Properties (IPs) of the model vendors. To ensure reliable commercialization of deep learning models, it is crucial to develop techniques to protect model vendors against IP infringements. One of such techniques that recently has shown great promise is digital watermarking. However, current watermarking approaches can embed very limited amount of information and are vulnerable against watermark removal attacks. In this paper, we present GradSigns, a novel watermarking framework for deep neural networks (DNNs). GradSigns embeds the owner's signature into the gradient of the cross-entropy cost function with respect to inputs to the model. Our approach has a negligible impact on the performance of the protected model and it allows model vendors to remotely verify the watermark through prediction APIs.</p>
                <p class="c-card__link-caption">Check my paper and presentation:</p>
                <a class="c-card__link" href="https://arxiv.org/abs/2103.03701">Don't Forget to Sign the Gradients!</a>
                <a class="c-card__link" href="https://slideslive.com/38952716/dont-forget-to-sign-the-gradients?ref=recommended">My presentation on MLSys-21</a>
              </div>
            </div>
            <div class="c-card__button">
              <button class="c-card__button-field" type="button"></button>
            </div>
          </div>

          <div class="c-card__item js-toggle-modal">
            <div class="c-card__sizer"></div>
            <div class="c-card__inner">
              <div class="c-card__icon">
                
              </div>
              <h4 class="c-card__header">Machine Learning For Hardware Security</h4>
              <div class="c-card__content js-card-content">
              </div>
              <div class="c-card__modal-content js-card-modal-content">
                <p align="left" class="c-card__text">Physical Unclonable Function (PUF) is seen as a promising alternative to traditional cryptographic algorithms for secure and lightweight device authentication for the diverse IoT use cases. However, the essential security of PUF is threatened by a kind of machine learning (ML) based modeling attacks which could successfully impersonate the PUF by using known challenge and response pairs (CPRs). However, existing modeling methods require access to an extremely large set of CRPs which makes them unrealistic and impractical in the real world scenarios. To handle the limitation of available CRPs from the attack perspective, we explore the possibility to transfer a well-tuned model trained with unlimited CRPs to a target PUF with limited number of CRPs.</p>
                <p class="c-card__link-caption">Check my papers:</p>
                <a class="c-card__link" href="https://ieeexplore.ieee.org/document/9137057">Efficient Transfer Learning on Modeling Physical Unclonable Functions</a>
                <a class="c-card__link" href="https://ieeexplore.ieee.org/document/9136972">Impacts of Machine Learning on Counterfeit IC Detection and Avoidance Techniques</a>
              </div>
            </div>
            <div class="c-card__button">
              <button class="c-card__button-field" type="button"></button>
            </div>
          </div>

          <div class="c-card__item js-toggle-modal">
            <div class="c-card__sizer"></div>
            <div class="c-card__inner">
              <div class="c-card__icon">
                
              </div>
              <h4 class="c-card__header">Genetic Algorithm For Designing Polymorphic Gates</h4>
              <div class="c-card__content js-card-content">
                <p class="c-card__text"></p>
              </div>
              <div class="c-card__modal-content js-card-modal-content">
                <p align="left" class="c-card__text">Polymorphic gates are reconfigurable devices whose functionality may vary in response to the change of execution environment such as temperature, supply voltage or external control signals. This feature makes them a perfect candidate for circuit watermarking. However, polymorphic gates are hard to find because they do not exhibit the traditional structure. My colleagues and I proposed a genetic algorithm based approach to address this challenge and were able to find many previously unseen polymorphic gates.</p>
              </div>
            </div>
            <div class="c-card__button">
              <button class="c-card__button-field" type="button"></button>
            </div>
          </div>

          <div class="c-card__item js-toggle-modal">
            <div class="c-card__sizer"></div>
            <div class="c-card__inner">
              <div class="c-card__icon">
                
              </div>
              <h4 class="c-card__header">Polymorphic Gates For IC Watermarking</h4>
              <div class="c-card__content js-card-content">
                <p class="c-card__text"> </p>
              </div>
              <div class="c-card__modal-content js-card-modal-content">
                <p align="left" class="c-card__text">My colleagues and I aimed to dig out the potentials of polymorphic circuits in hardware security and trust related applications, which hasn not been comprehensively researched in previous works. One straightforward and convenient application of polymorphic gates is to embed circuit watermark, which is one of the first studied hardware security problems. In this scheme, the circuit delivers correct functionality in the normal mode; when it is necessary to demonstrate the watermark, the circuit is transitioned to the special mode by activating the external control so that the circuit can change its functionality and produce different outputs. In this case, the hidden “secret” is the hardware-level watermark, which proves the ownership of the circuits andgives the circuits legal protection against piracy, overbuilding and counterfeiting.</p>
                <p class="c-card__link-caption">Check my paper:</p>
                <a class="c-card__link" href="https://par.nsf.gov/servlets/purl/10075440">Polymorphic Gate based IC Watermarking Techniques</a>
              </div>
            </div>
            <div class="c-card__button">
              <button class="c-card__button-field" type="button"></button>
            </div>
          </div>

          <div class="c-card__item js-toggle-modal">
            <div class="c-card__sizer"></div>
            <div class="c-card__inner">
              <div class="c-card__icon">
                
              </div>
              <h4 class="c-card__header">Polymorphic Gates For IC Fingerprinting</h4>
              <div class="c-card__content js-card-content">
                <p class="c-card__text"></p>
              </div>
              <div class="c-card__modal-content js-card-modal-content">
                <p align="left" class="c-card__text"> My colleagues and I proposed a circuit fingerprinting scheme with polymorphic gates controlled by external inputs. The scheme targets SDC (Satisfiability Don’t Care) conditions that usually appear in non-trivial circuits and replaces the standard library cells holding the SDC conditions by polymorphic gates. The modified circuit delivers correct functionality and the configurations of the polymorphic gates constitute the circuit fingerprint.</p>
                <p class="c-card__link-caption">Check my papers:</p>
                <a class="c-card__link" href="https://dl.acm.org/doi/pdf/10.1145/3194554.3194572">A Novel Polymorphic Gate Based Circuit Fingerprinting Technique</a>
              </div>
            </div>
            <div class="c-card__button">
              <button class="c-card__button-field" type="button"></button>
            </div>
          </div>

          <div class="c-card__item js-toggle-modal">
            <div class="c-card__sizer"></div>
            <div class="c-card__inner">
              <div class="c-card__icon">
                
              </div>
              <h4 class="c-card__header">Polymorphic Gates For Circuit Authentication</h4>
              <div class="c-card__content js-card-content">
                <p class="c-card__text"></p>
              </div>
              <div class="c-card__modal-content js-card-modal-content">
                <p align="left" class="c-card__text">Polymorphic gates are reconfigurable electronic devices that exhibit multiple functionalities under different environments such as temperature, supply voltage, or external signals. Such gates are rare as they do not have a complementary topology and need to satisfy the input-output relationships for more than one functionality. My colleagues and I introduced the concept of partial polymorphic gates, which deliver multiple incomplete functions with non-deterministic outputs at certain input combinations. The non-deterministic output is a result of process variations, which are generally believed to be random, unclonable, and different from chip to chip. We utilize this uncertainty as a new mechanism for implementing chip IDs and propose a circuit authentication scheme based on such IDs.</p>
                <p class="c-card__link-caption">Check my paper:</p>
                <a class="c-card__link" href="https://ieeexplore.ieee.org/abstract/document/9699513">A Novel Circuit Authentication Scheme Based on Partial Polymorphic Gates</a>
              </div>
            </div>
            <div class="c-card__button">
              <button class="c-card__button-field" type="button"></button>
            </div>
          </div>

          <div class="c-card__item js-toggle-modal">
            <div class="c-card__sizer"></div>
            <div class="c-card__inner">
              <div class="c-card__icon">
                
              </div>
              <h4 class="c-card__header">Scan-chain Based Authentication Framework for Embedded Systems</h4>
              <div class="c-card__content js-card-content">
              </div>
              <div class="c-card__modal-content js-card-modal-content">
                <p align="left" class="c-card__text">Most of the Internet of Things (IoT) and embedded devices are resource constrained, making it impractical to secure them with the traditional computationally expensive crypto-based solutions. However, security and privacy are crucial in many IoT applications such as health monitoring. In this paper, we consider one of the most fundamental security problems: how to identify and authenticate an embedded device. We consider the fact that embedded devices are designed by reusing IP cores with reconfigurable scan network (RSN) as the standard testing facility and propose to generate unique integrated circuit (IC) identifications (IDs) based on different configurations for the RSN. These circuit IDs not only solve the IC and device identification and authentication problems, they can also be considered as a lightweight security primitive in other applications such as IC metering and IP fingerprinting.</p>
                <p class="c-card__link-caption">Check my paper:</p>
                <a class="c-card__link" href="https://past.date-conference.com/proceedings-archive/2018/pdf/1036.pdf">A Reconfigurable Scan Network Based IC Identification For Embedded Devices</a>
              </div>
            </div>
            <div class="c-card__button">
              <button class="c-card__button-field" type="button"></button>
            </div>
          </div>

        </div>
      </div>
    </div>
  </div>

  <!-- ML PUBLICATIONS -->
  <div id="section-publications" class="o-container   wow1 fadeIn"  data-contentPosition="4">
    <div class="c-section-heading">
      <h2 class="c-section-heading__header">Publications On Machine Learning</h2>
    </div>
    <div class="c-screen-publications o-screen-publications">
      <div class="o-screen-publications__col">
        <div class="c-article">

          <div class="c-article__item">
            <div class="c-article__body">
              <h3 class="c-article__header">Meta Federated Learning</h3>
              <p class="c-article__cite">Distributed and Private Machine Learning Worshop in the International Conference on Learning Representations (ICLR-20)</p>
              <p class="c-article__text">Due to its distributed methodology alongside its privacy-preserving features, Federated Learning (FL) is vulnerable to training time adversarial attacks. In this study, our focus is on backdoor attacks in which the adversary's goal is to cause targeted misclassifications for inputs embedded with an adversarial trigger while maintaining an acceptable performance on the main learning task at hand. Contemporary defenses against backdoor attacks in federated learning require direct access to each individual client's update which is not feasible in recent FL settings where Secure Aggregation is deployed. In this study, we seek to answer the following question, Is it possible to defend against backdoor attacks when secure aggregation is in place?, a question that has not been addressed by prior arts. To this end, we propose Meta Federated Learning (Meta-FL), a novel variant of federated learning which not only is compatible with secure aggregation protocol but also facilitates defense against backdoor attacks. We perform a systematic evaluation of Meta-FL on two classification datasets: SVHN and GTSRB. The results show that Meta-FL not only achieves better utility than classic FL, but also enhances the performance of contemporary defenses in terms of robustness against adversarial attacks.</p>
            </div>
          </div>

          <div class="c-article__item">
            <div class="c-article__body">
              <h3 class="c-article__header">Don’t Forget to Sign the Gradients!</h3>
              <p class="c-article__cite">Proceedings of Machine Learning and Systems 3 (MLSys-21)</p>
              <p class="c-article__text">Engineering a top-notch deep learning model is an expensive procedure that involves collecting data, hiring human resources with expertise in machine learning, and providing high computational resources. For that reason, deep learning models are considered as valuable Intellectual Properties (IPs) of the model vendors. To ensure reliable commercialization of deep learning models, it is crucial to develop techniques to protect model vendors against IP infringements. One of such techniques that recently has shown great promise is digital watermarking. However, current watermarking approaches can embed very limited amount of information and are vulnerable against watermark removal attacks. In this paper, we present GradSigns, a novel watermarking framework for deep neural networks (DNNs). GradSigns embeds the owner's signature into the gradient of the cross-entropy cost function with respect to inputs to the model. Our approach has a negligible impact on the performance of the protected model and it allows model vendors to remotely verify the watermark through prediction APIs. We evaluate GradSigns on DNNs trained for different image classification tasks using CIFAR-10, SVHN, and YTF datasets. Experimental results show that GradSigns is robust against all known counter-watermark attacks and can embed a large amount of information into DNNs.</p>
            </div>
          </div>

          <div class="c-article__item">
            <div class="c-article__body">
              <h3 class="c-article__header">Provably Accurate Memory Fault Detection Method for Deep Neural Networks</h3>
              <p class="c-article__cite">Proceedings of the 2021 on Great Lakes Symposium on VLSI (GLSVLSI-21)</p>
              <p class="c-article__text">Deep Neural Networks (DNNs) have been widely deployed in real-world systems, many of which have strict safety constraints. Soft errors on memory acceleration platforms for DNNs can degrade their inference accuracy and result in silent data corruption, which can have severe consequences in safety-critical applications. No doubt to say, efficient and effective techniques to detect and mitigate memory faults are needed. In this paper, we propose a novel methodology to diagnose the presence of faults in the memory of DNN accelerators. Our method queries the protected DNN with a set of specially crafted test cases that can accurately reveal if model parameters stored in the hardware are faulty. We provide a theoretical guarantee for the performance of our method and conduct systematic proof-of-concept experiments by simulating memory faults on computer vision models. Our empirical evaluations corroborate the effectiveness and efficiency of our approach. Detecting faults with our method requires simple decision-based access to the inference capability of the DNN, and does not require any additional functionality from the accelerator, which makes our method ideal for legacy systems.</p>
            </div>
          </div>

          <div class="c-article__item">
            <div class="c-article__body">
              <h3 class="c-article__header">AID: Attesting the Integrity of Deep Neural Networks</h3>
              <p class="c-article__cite">2021 58th ACM/IEEE Design Automation Conference (DAC-21)</p>
              <p class="c-article__text">Due to their crucial role in many decision-making tasks, Deep Neural Networks (DNNs) are common targets for a large array of integrity breaches. In this paper, we propose AID, a novel methodology to Attest the Integrity of DNNs. AID generates a set of test cases called edge-points that can reveal whether a model has been compromised. AID does not require access to parameters of the DNN and can work with a restricted black-box access to the model, which makes it applicable to most real life scenarios. Experimental results show that AID is highly effective and reliable. With at most four edge-points, AID is able to detect eight representative integrity breaches including backdoor, poisoning, and compression attacks, with zero false-positive.</p>
            </div>
          </div>

          <div class="c-article__item">
            <div class="c-article__body">
              <h3 class="c-article__header">Trust in Machine Learning as a Service</h3>
              <p class="c-article__cite">PhD Forum Paper on System on Chip Conference (SOCC-20)</p>
              <p class="c-article__text">While MLaaS platforms have made it convenient for model vendors to deploy and monetize their products, they raise immediate security and trust concerns. In this paper, we talk about research problems that need to be addressed before reliable and secure commercialization of DNNs on MLaaS platforms would be possible.</p>
            </div>
          </div>

          <div class="c-article__item">
            <div class="c-article__body">
              <h3 class="c-article__header">Do You Sign Your Model?</h3>
              <p class="c-article__cite">DMMLSys workshop in International Conference on Machine Learning (ICML-20)</p>
              <p class="c-article__text">Engineering a top-notch deep neural network (DNN) is an expensive procedure which involves collecting data, hiring human resources with expertise in machine learning, and providing high computational resources. For that reason, DNNs are considered as valuable Intellectual Properties (IPs) of the model vendors. To ensure a reliable commercialization of these products, it is crucial to develop techniques to protect model vendors against IP infringements. One of such techniques that recently has shown great promise is digital watermarking. In this paper, we present GradSigns, a novel watermarking framework for DNNs. GradSigns embeds owner's signature into gradient of cross-entropy cost function with respect to inputs to the model. Our approach has negligible impact on the performance of the protected model, and can verify ownership of remotely deployed models through prediction APIs. We evaluate GradSigns on DNNs trained for different image classification tasks using CIFAR-10, SVHN and YTF datasets, and experimentally show that unlike existing methods, GradSigns is robust against counter-watermark attacks, and can embed large amount of information into DNNs.</p>
            </div>
          </div>

      </div>
    </div>
  </div>


  <!-- hWS PUBLICATIONS -->
  <div id="section-publications-1" class="o-container   wow1 fadeIn"  data-contentPosition="5">
    <div class="c-section-heading">
      <h2 class="c-section-heading__header"> Publications on Hardware Security</h2>
    </div>

    <div class="c-screen-publications o-screen-publications">
      <div class="o-screen-publications__col">
        <div class="c-article">

          <div class="c-article__item">
            <div class="c-article__body">
              <h3 class="c-article__header">Independent Verification and Validation of Security-Aware CAD Tools</h3>
              <p class="c-article__cite">2021 58th ACM/IEEE Design Automation Conference (DAC-21)</p>
              <p align="left" class="c-article__text">Due to its distributed methodology alongside its privacy-preserving features, Federated Learning (FL) is vulnerable to training time adversarial attacks. In this study, our focus is on backdoor attacks in which the adversary's goal is to cause targeted misclassifications for inputs embedded with an adversarial trigger while maintaining an acceptable performance on the main learning task at hand. Contemporary defenses against backdoor attacks in federated learning require direct access to each individual client's update which is not feasible in recent FL settings where Secure Aggregation is deployed. In this study, we seek to answer the following question, Is it possible to defend against backdoor attacks when secure aggregation is in place?, a question that has not been addressed by prior arts. To this end, we propose Meta Federated Learning (Meta-FL), a novel variant of federated learning which not only is compatible with secure aggregation protocol but also facilitates defense against backdoor attacks. We perform a systematic evaluation of Meta-FL on two classification datasets: SVHN and GTSRB. The results show that Meta-FL not only achieves better utility than classic FL, but also enhances the performance of contemporary defenses in terms of robustness against adversarial attacks.</p>
            </div>
          </div>

          <div class="c-article__item">
            <div class="c-article__body">
              <h3 class="c-article__header">A Novel Circuit Authentication Scheme based on Partial Polymorphic Gates</h3>
              <p class="c-article__cite">Asian Hardware Oriented Security and Trust Symposium (AsianHOST-21)</p>
              <p align="left" class="c-article__text">Engineering a top-notch deep learning model is an expensive procedure that involves collecting data, hiring human resources with expertise in machine learning, and providing high computational resources. For that reason, deep learning models are considered as valuable Intellectual Properties (IPs) of the model vendors. To ensure reliable commercialization of deep learning models, it is crucial to develop techniques to protect model vendors against IP infringements. One of such techniques that recently has shown great promise is digital watermarking. However, current watermarking approaches can embed very limited amount of information and are vulnerable against watermark removal attacks. In this paper, we present GradSigns, a novel watermarking framework for deep neural networks (DNNs). GradSigns embeds the owner's signature into the gradient of the cross-entropy cost function with respect to inputs to the model. Our approach has a negligible impact on the performance of the protected model and it allows model vendors to remotely verify the watermark through prediction APIs. We evaluate GradSigns on DNNs trained for different image classification tasks using CIFAR-10, SVHN, and YTF datasets. Experimental results show that GradSigns is robust against all known counter-watermark attacks and can embed a large amount of information into DNNs.</p>
            </div>
          </div>

          <div class="c-article__item">
            <div class="c-article__body">
              <h3 class="c-article__header">Impacts of Machine Learning on Counterfeit IC Detection and Avoidance Techniques</h3>
              <p class="c-article__cite">21st International Symposium on Quality Electronic Design (ISQED-20)</p>
              <p align="left" class="c-article__text">Globalization of integrated circuit (IC) supply chain has made counterfeiting a major source of concern in the semiconductor industry. To address this concern, extensive efforts have been put into developing effective counterfeit detection and avoidance techniques. In the recent years, machine learning (ML) algorithms have played an important role in development and evaluation of many emerging countermeasures against counterfeiting. In this paper, we aim to investigate impacts of such algorithms on the landscape of anti-counterfeiting schemes. We provide a comprehensive review of prior arts that deploy machine learning to develop or attack counterfeit detection and avoidance techniques. We also discuss future directions for application of machine learning in anti-counterfeit schemes.</p>
            </div>
          </div>

          <div class="c-article__item">
            <div class="c-article__body">
              <h3 class="c-article__header">Efficient Transfer Learning Attack for Modeling Physical Unclonable Functions</h3>
              <p class="c-article__cite">21st International Symposium on Quality Electronic Design (ISQED-20)</p>
              <p align="left" class="c-article__text">Physical Unclonable Function (PUF) is seen as a promising alternative to traditional cryptographic algorithms for secure and lightweight device authentication for the diverse IoT use cases. However, the essential security of PUF is threatened by a kind of machine learning (ML) based modeling attacks which could successfully impersonate the PUF by using known challenge and response pairs (CPRs). However, existing modeling methods require access to an extremely large set of CRPs which makes them unrealistic and impractical in the real world scenarios. To handle the limitation of available CRPs from the attack perspective, we explore the possibility to transfer a well-tuned model trained with unlimited CRPs to a target PUF with limited number of CRPs. Experimental results show that the proposed transfer learning-based scheme could achieve the same accuracy level with 64% less of CRPs in average. Besides, we also evaluate the proposed transfer learning method with side-channel information and it demonstrates in reducing the number of CRPs significantly.</p>
            </div>
          </div>

          <div class="c-article__item">
            <div class="c-article__body">
              <h3 class="c-article__header">Balancing Testability and Security by Configurable Partial Scan Design</h3>
              <p class="c-article__cite">2018 IEEE International Test Conference in Asia (ITC-Asia-18)</p>
              <p align="left" class="c-article__text">Scan chain design facilitates chip testing by providing an interface for the test engineers to access and control the internal states of the circuit. This feature has also been exploited to break systems such as the cryptographic chips by the attack known as scan chain side channel analysis. From the perspective of information access, test engineers and scan chain attackers have the same goal - observe and control the scan chain side channel information. Consequently, all the existing countermeasures have to make the tradeoff between scan chain security and the testability it can provide. In this paper, we propose a novel public-private partial scan chain design which can deliver both full testability and security. The key idea is to partition the flip flops into a public partial chain and a set of parallel private partial chains. The private partial chains are protected by means of a hardware implemented finite state machine and an obfuscation mechanism based on configurable physical unclonable function. We demonstrate how full testability can be achieved by the proposed public-private partial chains. We conduct security and performance analysis to show that our approach is robust against all the known scan chain based attacks and can improve testing time and power consumption with negligible hardware overhead.</p>
            </div>
          </div>

          <div class="c-article__item">
            <div class="c-article__body">
              <h3 class="c-article__header">A Reconfigurable Scan Network based IC Identification for Embedded Devices</h3>
              <p class="c-article__cite">2018 Design, Automation & Test in Europe Conference & Exhibition (DATE-18)</p>
              <p align="left" class="c-article__text">Most of the Internet of Things (IoT) and embedded devices are resource constrained, making it impractical to secure them with the traditional computationally expensive crypto-based solutions. However, security and privacy are crucial in many IoT applications such as health monitoring. In this paper, we consider one of the most fundamental security problems: how to identify and authenticate an embedded device. We consider the fact that embedded devices are designed by reusing IP cores with reconfigurable scan network (RSN) as the standard testing facility and propose to generate unique integrated circuit (IC) identifications (IDs) based on different configurations for the RSN. These circuit IDs not only solve the IC and device identification and authentication problems, they can also be considered as a lightweight security primitive in other applications such as IC metering and IP fingerprinting. We demonstrate through the ITC'02 benchmarks that the proposed approach can easily create from 10 7 to 10 186 unique IDs without any overhead. Finally, our method complies with the IEEE standards and thus has high practical value.</p>
            </div>
          </div>

         
          <div class="c-article__item">
            <div class="c-article__body">
              <h3 class="c-article__header">A Novel Polymorphic Gate based Circuit Fingerprinting Technique</h3>
              <p class="c-article__cite">2018 IEEE International Symposium on Circuits and Systems (ISCAS-18)</p>
              <p align="left" class="c-article__text">Polymorphic gates are reconfigurable devices that deliver multiple functionalities at different temperature, supply voltage or external inputs. Capable of working in different modes, polymorphic gate is a promising candidate for embedding secret information such as fingerprints. In this paper we report five polymorphic gates whose functionality varies in response to specific control input and propose a circuit fingerprinting scheme based on these gates. The scheme selectively replaces standard logic cells by polymorphic gates whose functionality differs with the standard cells only on Satisfiability Don't Care conditions. Additional dummy fingerprint bits are also introduced to enhance the fingerprint's robustness against attacks such as fingerprint removal and modification. Experimental results on ISCAS and MCNC benchmark circuits demonstrate that our scheme introduces low overhead. More specifically, the average overhead in area, speed and power are 4.04%, 6.97% and 4.15% respectively when we embed 64-bit fingerprint that consists of 32 real fingerprint bits and 32 dummy bits. This is only half of the overhead of the other known approach when they create 32-bit fingerprints.</p>
            </div>
          </div>

          <div class="c-article__item">
            <div class="c-article__body">
              <h3 class="c-article__header">Polymorphic Gate based IC Watermarking Techniques</h3>
              <p class="c-article__cite">Asia and South Pacific Design Automation Conference (ASP-DAC-18)</p>
              <p align="left" class="c-article__text">Polymorphic gates are reconfigurable devices whose functionality may vary in response to the change of execution environment such as temperature, supply voltage or external control signals. This feature makes them a perfect candidate for circuit watermarking. However, polymorphic gates are hard to find because they do not exhibit the traditional structure. In this paper, we report four dual-function polymorphic gates that we have discovered using an evolutionary approach. With these gates, we propose a circuit watermarking scheme that selectively replaces certain standard logic gates with the polymorphic gates. Experimental results on ISCAS and MCNC benchmark circuits demonstrate that this scheme introduces low overhead. More specifically, the average overhead in area, speed and power are 4.10%, 2.08% and 1.17% respectively when we embed 30-bit watermark sequences. These overheads increase to 6.36%, 4.75% and 2.08% respectively when 10% of the gates in the original circuits are replaced to embed watermark up to more than 300 bits.</p>
            </div>
          </div>
      </div>
    </div>
  </div>

  
  <!-- CONTACT -->
  <div id="section-contacts" class="o-container   wow1 fadeIn"  data-contentPosition="6">
    <div class="c-section-heading">
      <h2 class="c-section-heading__header">Contact</h2>
    </div>

    <div class="c-screen-contact o-screen-contact">
      <div class="o-screen-contact__col-info">
        <a class="c-screen-contact__item" href="mailto:oaramoon@umd.edu">oaramoon@umd.edu</a>
        <a class="c-screen-contact__item" href="tel:+14439681638">+1 (443) 968 1638</a>
        <ul class="c-socials u-mb-20">
          <li class="c-socials__item">
            <a href="http://www.linkedin.com/in/omid-aramoon" class="c-socials__link">
              <i class="icofont icofont-brand-linkedin"></i>
            </a>
          </li>
          <li class="c-socials__item">
            <a href="https://github.com/oaramoon" class="c-socials__link">
              <i class="icofont icofont-social-github"></i>
          </a>
         </li>
          
        </ul>
        <ul class="c-screen-contact__address">
          <li>1430 AVW Building,</li>
          <li>Department of Electrical and Computer Engineering</li>
          <li>University of Maryland, College Park, MD</li>
        </ul>
      </div>
      <div class="o-screen-contact__col-form">
        <form class="c-form js-form-validation" action="#" method="get">
          <label for="contact-name">Your name</label>
          <input class="c-form__field" id="contact-name" type="text" placeholder="Peter Parker, for example" required>
          <label for="contact-email">Your e-mail</label>
          <input class="c-form__field" id="contact-email" type="email" placeholder="yourmail@mail.com" required>
          <label for="contact-message">Message text</label>
          <textarea class="c-form__field" id="contact-message" name="name" placeholder="Write here your question or interesting offer" required></textarea>
          <fieldset class="u-text-right">
            <button class="c-button c-button--primary" type="submit" name="contact-submit">send a message</button>
          </fieldset>
        </form>
      </div>
    </div>
  </div>
</main>




      <footer class="c-main-footer js-main-footer">
  <div id="contact-map" class="c-main-footer__map">
  </div>
  <div class="c-main-footer__top o-container js-main-footer-top"></div>
  <div class="c-main-footer__bottom js-main-footer-bottom">
  </div>
</footer>

    </div>

    <script src="components/jquery.min.js"></script>
    <script src="components/wow.min.js"></script>
    <script src="js/jquery.waypoints.min.js"></script>
    <script src="js/inview.min.js"></script>
    <script src="js/main.js"></script>


</body>
</html>
